{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_RNN_v3_train_ipynb_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# GPU 가능하다면 GPU 활용 ( 런타임-> 런타임 유형 변경 -> 가속기 -> GPU )"
      ],
      "metadata": {
        "id": "OGfSJ4I5Qj7m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhiEVMu8HPOi",
        "outputId": "366572aa-4104-4584-dde9-b033bc92bf27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python -V"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 혹시 버전일치 안될 때\n",
        "!apt install python3.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5sJbldHHjmN",
        "outputId": "4ea7bc66-1a49-4198-93c8-99350ab8a15c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3.7 is already the newest version (3.7.13-1+bionic3).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svEgHVX0HyqV",
        "outputId": "f9efdbfe-550b-4e56-df28-d6f7dbaa92b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.12.0+cu113)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 12.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (4.1.1)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.0\n",
            "    Uninstalling torchtext-0.13.0:\n",
            "      Successfully uninstalled torchtext-0.13.0\n",
            "Successfully installed sentencepiece-0.1.96 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52Q-LDxEIOBU",
        "outputId": "c89f09e7-fd10-40de-c652-08ed7aaaebf7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.7)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext import data # Field 불러온 이 양식은 torchtext 0.6 버전에 맞춘 것\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language='en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype=torch.float) # pos -> 1 : neg -> 0"
      ],
      "metadata": {
        "id": "WXpg0qkNIVVE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMDB 불러오기\n",
        "\n",
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvmBY5vRJYCl",
        "outputId": "0223a5b0-3766-47e2-a37b-c81821d7b59a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:02<00:00, 34.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'train_data : {len(train_data)}')\n",
        "print(f'test_data : {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW3GvAeWJ1xN",
        "outputId": "007e7585-e5ee-4ffe-8efe-c93b04367f48"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data : 25000\n",
            "test_data : 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqjYAPICKRh0",
        "outputId": "e8acc407-9116-40ca-b626-779aecad8cbd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['This', 'was', 'an', 'adorable', 'movie', '.', 'A', 'real', 'feel', '-', 'good', 'movie', 'when', 'you', 'need', 'one', '.', 'The', 'story', 'is', 'light', '(', 'this', 'is', 'no', 'Gone', 'With', 'the', 'Wind', ')', 'but', 'sometimes', ',', 'one', 'needs', 'this', 'kind', 'of', 'plot', '.', 'Funny', 'and', 'warm', 'characters', ',', 'fantastic', 'acting', 'and', 'beautiful', 'costumes', '/', 'wardrobe.<br', '/><br', '/>Parminder', 'K.', 'Nagra', '(', 'also', 'from', 'the', 'TV', 'show', 'ER', ')', 'is', 'WONDERFUL', 'in', 'this', 'role', '.', 'She', 'is', 'definitely', 'a', 'new', 'shining', 'star', 'for', 'Hollywood', '.', 'All', 'should', 'keep', 'an', 'eye', 'on', 'her', ',', 'she', \"'s\", 'going', 'to', 'be', 'BIG', 'in', 'the', 'future.<br', '/><br', '/>Also', 'impressing', 'was', 'the', 'soundtrack', 'for', 'this', 'movie', '.', 'A', 'nice', 'mix', 'of', 'modern', 'and', 'Indian', 'tunes', '.', 'I', 'was', 'dancing', 'throughout', 'most', 'of', 'the', 'movie.<br', '/><br', '/>Highly', 'recommended', 'if', 'a', 'fun', 'movie', 'is', 'what', 'you', 'need', '.'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# valid data를 train data 중 일부로 분리해보려 함\n",
        "import random\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "# 컴퓨팅 cudnn에 해당\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "metadata": {
        "id": "LAOIPf6GLrNl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'train_data : {len(train_data)}')\n",
        "print(f'valid_data : {len(valid_data)}')\n",
        "print(f'test_data : {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCza20VeMUit",
        "outputId": "f4b8586d-d395-4c61-95e9-475293d7d818"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data : 17500\n",
            "valid_data : 7500\n",
            "test_data : 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocab  빌드하기\n",
        "\n",
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE, min_freq=5)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "k-iYEPKyNG11"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 25002인 이유 : <unk>, <pad>   두 토큰 때문. <pad> 문장의 길이를 맞추는 token\n",
        "print(f'Unique tokens in TEXT vocab: {len(TEXT.vocab)}')\n",
        "print(f'Unique tokens in LABEL vocab: {len(LABEL.vocab)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4HipgodN5OJ",
        "outputId": "c94f601f-1a27-4899-99e1-a43f5475c716"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocab: 25002\n",
            "Unique tokens in LABEL vocab: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'가장 자주 나오는 단어들 10개 in TEXT: \\n{TEXT.vocab.freqs.most_common(10)}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg0W-tO2OcKV",
        "outputId": "9e2d99b0-84d7-4472-9d10-6174e2e9b439"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가장 자주 나오는 단어들 10개 in TEXT: \n",
            "[('the', 201623), (',', 191855), ('.', 165297), ('a', 109153), ('and', 108995), ('of', 100435), ('to', 93378), ('is', 75991), ('in', 61082), ('I', 54034)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.itos[:3]) # int to string\n",
        "print(LABEL.vocab.stoi) # string to int"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KZUmzqkO1_E",
        "outputId": "2b116456-404d-4107-b83a-ea034898674f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', 'the']\n",
            "defaultdict(None, {'neg': 0, 'pos': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# interator\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7sLFSujPPIR",
        "outputId": "f696fe58-4b2d-4df5-80b6-6c8a64089190"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if 'gpu 지원 되면' else'cpu'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "UdNnEvbmRHbF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device\n",
        ")"
      ],
      "metadata": {
        "id": "4yxPKzvuThDE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iterator활용\n",
        "for i, batch in enumerate(train_iterator):\n",
        "    text = batch.text\n",
        "    label = batch.label\n",
        "\n",
        "    #print(f'배치의 text 크기: {text.shape}')\n",
        "    #print('text[3]', text[3])\n",
        "    #print(f'배치의 label 크기: {label.shape}')\n",
        "    #print('label', label)\n"
      ],
      "metadata": {
        "id": "aNVDxk6CT7E2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 build\n",
        "\n",
        "# Embedding layer:   input -> 숫자로된 vector로 매핑하는데 look-up table\n",
        "# 신경망에서 가중치가 업데이트 되는 방식처럼  역전파 때 학습\n",
        "\n",
        "# RNN layer (함수 정의)\n",
        "# RNN  문장 속에 단어들을 한번에 하나씩 계산하여 각 단어당 hidden state(h)를 도출\n",
        "# h_t = RNN (x_t, h_(t-1))\n",
        "# 마지막 hidden state   h_T 를 linear layer에 통과시키면   최종 prediction   y_hat = f(h_T)"
      ],
      "metadata": {
        "id": "Fwodnf20U_iF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "5nPNhSygWPO0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "      super().__init__()\n",
        "\n",
        "      self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "      self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "      self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "      # text = [sentence length, batch size]\n",
        "      embedded = self.embedding(text)\n",
        "\n",
        "      # embedded = [sentence length, batch size, embedding dim]\n",
        "\n",
        "      output, hidden = self.rnn(embedded)\n",
        "\n",
        "      # output = [sentence length, batch size, hidden dim]\n",
        "      # hidden = [1, batch size, hidden dim]\n",
        "\n",
        "      return self.fc(hidden.squeeze(0))"
      ],
      "metadata": {
        "id": "xQQXDcS6WUQ1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " -input_dim: 단어 사이즈\n",
        " -embedding_dim: 보통 50-250 차원\n",
        " -hidden_dim: 대개 100-500 차원\n",
        " -output_dim: class 수,  0 vs 1   1차원"
      ],
      "metadata": {
        "id": "A-ycazQDX4I7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab) # 25002\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "metadata": {
        "id": "pLDo1BqLXzek"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Trainable Param num : {count_parameters(model):,}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igitghdpYxMl",
        "outputId": "27469c48-4a55-4b59-b612-a7144a3c770c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable Param num : 2,592,105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "wLgEf7LnZbG1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "VJR3BO6KZeY0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function    binary crossentropy with logits\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "-hwP2S2upFkY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "HZ803BOVpW-5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy func\n",
        "def binary_accuracy(preds, y):\n",
        "  rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "  # rounded_preds : [batch size]\n",
        "  # y : batch.label\n",
        "\n",
        "  correct = (rounded_preds == y).float() # 정답지 true/false\n",
        "  acc = correct.sum() / len(correct)\n",
        "  return acc"
      ],
      "metadata": {
        "id": "0WWkUBsPpoYh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.train() # model을 train 모드로 전환. dropout이나 batch normalization 가능해짐\n",
        "\n",
        "  for batch in iterator:\n",
        "    # batch마다 gradient를 0으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 문자의 batch -> batch.text 이것을 model에 입력 -> forward 수행\n",
        "    # predictions의 크기가 [batch size, 1] 이므로,  스퀴즈 해서 [batch size]로 shape 변경\n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "\n",
        "    # acc, loss\n",
        "    acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "    loss = criterion(predictions, batch.label)\n",
        "    # backward() 사용하여 역전파\n",
        "    loss.backward()\n",
        "\n",
        "    # 최적화알고리즘으로 parameter 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "O6KNQp7nqjhS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  # evalute mode\n",
        "  model.eval()\n",
        "\n",
        "  # pytorch가 평가시점엔 gradient 계산 안해도 될때이므로 멈춰서 memory 아끼고, 계산 속도 높도록\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "\n",
        "        # acc, loss\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "        loss = criterion(predictions, batch.label)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "metadata": {
        "id": "uw1LiM5_sxyZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time/60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "kAE1jQdkuJqg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learning  through epochs"
      ],
      "metadata": {
        "id": "7asK9ujyuoGw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start_time = time.time()\n",
        "\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "  end_time = time.time()\n",
        "\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'tut1-model.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYB-V5Ylut24",
        "outputId": "bf753aea-fa9d-4396-8387-8d3ff423d9a0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.694 | Train Acc: 49.79%\n",
            "\tValid Loss: 0.696 | Valid Acc: 49.61%\n",
            "Epoch: 02 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.18%\n",
            "\tValid Loss: 0.696 | Valid Acc: 50.78%\n",
            "Epoch: 03 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.71%\n",
            "\tValid Loss: 0.696 | Valid Acc: 49.61%\n",
            "Epoch: 04 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.16%\n",
            "\tValid Loss: 0.696 | Valid Acc: 50.93%\n",
            "Epoch: 05 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.08%\n",
            "\tValid Loss: 0.696 | Valid Acc: 49.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))"
      ],
      "metadata": {
        "id": "l2LcKsmPxwdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf85e417-800f-4ba8-84c7-71f0839fea41"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'\\ttest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2odlkuzdx3fK",
        "outputId": "47661fac-1a37-41c8-e292-b7216dd938b8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ttest Loss: 0.709 | Test Acc: 47.33%\n"
          ]
        }
      ]
    }
  ]
}